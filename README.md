# Predictive Analytics System for NBA Roster Success

This project is an end-to-end sports analytics system that predicts the probability of an NBA team winning the championship based on a user-selected roster.  
It combines **machine learning**, **deep learning**, and an interactive **Streamlit** interface to allow users to build teams under salary-cap constraints and receive real-time predictions.

---

## ğŸ€ What the Project Does
- **Data Preprocessing**: Cleans, aggregates, and formats NBA player statistics with salary data.
- **Feature Engineering**: Aggregates individual player features into team-level metrics.
- **Model Training**: Trains multiple models (Logistic Regression, Random Forest, XGBoost, PyTorch Neural Network) with hyperparameter tuning.
- **Probability Calibration**: Improves reliability of predicted probabilities using Platt scaling/Isotonic regression.
- **Soft-Vote Ensembling**: Combines the best models to improve accuracy and F1 score.
- **Interactive App**: Streamlit-based UI where users build rosters and see predictions instantly.
- **AWS S3 Integration**: Stores and retrieves trained models from the cloud for flexible deployment.

---

## ğŸ”„ Pipeline Overview
1. **Data Acquisition & Cleaning** (`src/data/`):
   - Collect player stats and salaries.
   - Handle missing values and format columns.
   
2. **Feature Engineering** (`src/user_team_simulator/roster_features.py`):
   - Aggregate player-level features into a single team vector.
   - Create advanced metrics for better predictive power.

3. **Model Training & Evaluation** (`src/user_team_simulator/train_roster.py`):
   - Train multiple ML/DL models.
   - Evaluate on accuracy, F1 score, and calibration metrics.

4. **Probability Calibration & Ensembling** (`src/user_team_simulator/calibrate_and_ensemble.py`):
   - Apply calibration techniques to improve probability estimates.
   - Combine models via soft-vote ensembling.

5. **Deployment via Streamlit** (`frontend/team_builder.py`):
   - Users select players within a salary cap.
   - Backend aggregates features, loads the trained model, and outputs championship probability.
   - Supports both **local models** and **models from AWS S3**.

---

## ğŸ“‚ Folder Structure
```
â”œâ”€â”€ data/                         # Processed datasets
â”‚   â”œâ”€â”€ raw/                      # Raw CSV files
â”‚   â”œâ”€â”€ processed/                # Cleaned and feature-engineered CSV files
â”‚   â””â”€â”€ testing/                  # Test files
â”œâ”€â”€ models/                       # Trained models (local storage)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ historial_preductor/      # Data cleaning scripts
â”‚   â”œâ”€â”€ user_team_simulator/      # Feature engineering, training, calibration, and 
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ team_builder.py           # Streamlit app for user interaction
â”‚   â””â”€â”€ historial_preductor.py    # Streamlit app for user interaction
â”œâ”€â”€ results/                      # Model evaluation 
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project documentation
```
---

**Tech Stack:** Python Â· PyTorch Â· scikit-learn Â· XGBoost Â· Pandas Â· Streamlit Â· AWS S3  
**Key Skills:** Machine Learning, Deep Learning, Data Preprocessing, Feature Engineering, Model Calibration, Ensembling, Cloud Model Hosting